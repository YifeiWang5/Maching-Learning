{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab:  Logistic Regression for Gene Expression Data\n",
    "\n",
    "In this lab, we use logistic regression to predict biological characteristics (\"phenotypes\") from gene expression data.  In doing this lab, you will learn to:\n",
    "* Handle missing data\n",
    "* Perform multi-class logistic classification\n",
    "* Create a confusion matrix\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "Genes are the basic unit in the DNA and encode blueprints for proteins.  When proteins are synthesized from a gene, the gene is said to \"express\".  Micro-arrays are devices that measure the expression levels of large numbers of genes in parallel.  By finding correlations between expression levels and phenotypes, scientists can identify possible genetic markers for biological characteristics.\n",
    "\n",
    "The data in this lab comes from:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "\n",
    "In this data, mice were characterized by three properties:\n",
    "* Whether they had down's syndrome (trisomy) or not\n",
    "* Whether they were stimulated to learn or not\n",
    "* Whether they had a drug memantine or a saline control solution.\n",
    "\n",
    "With these three choices, there are 8 possible classes for each mouse.  For each mouse, the expression levels were measured across 77 genes.  We will see if the characteristics can be predicted from the gene expression levels.  This classification could reveal which genes are potentially involved in Down's syndrome and if drugs and learning have any noticeable effects.\n",
    "\n",
    "\n",
    "**Submission**:  Complete all sections labeled `#TODO`.  Run the notebook and print to PDF.  Submit the PDF.  Do not submit any other format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We begin by loading the standard modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pd.read_excel` command to read the data from \n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\n",
    "\n",
    "into a dataframe `df`.  Use the `index_col` option to specify that column 0 is the index.  Use the `df.head()` to print the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309_1</th>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_2</th>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_3</th>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>1.561316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_4</th>\n",
       "      <td>0.442107</td>\n",
       "      <td>0.617076</td>\n",
       "      <td>0.358626</td>\n",
       "      <td>2.466947</td>\n",
       "      <td>4.979503</td>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>2.152301</td>\n",
       "      <td>0.207004</td>\n",
       "      <td>1.595086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.147444</td>\n",
       "      <td>0.146901</td>\n",
       "      <td>1.700563</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_5</th>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>2.365785</td>\n",
       "      <td>4.718679</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>2.134014</td>\n",
       "      <td>0.192158</td>\n",
       "      <td>1.504230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110694</td>\n",
       "      <td>0.434154</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.148380</td>\n",
       "      <td>1.839730</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "MouseID                                                                         \n",
       "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
       "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
       "309_3    0.509183  0.730247  0.418309  2.687201  5.622059  0.209011  0.175722   \n",
       "309_4    0.442107  0.617076  0.358626  2.466947  4.979503  0.222886  0.176463   \n",
       "309_5    0.434940  0.617430  0.358802  2.365785  4.718679  0.213106  0.173627   \n",
       "\n",
       "         pCAMKII_N   pCREB_N    pELK_N  ...   pCFOS_N     SYP_N  H3AcK18_N  \\\n",
       "MouseID                                 ...                                  \n",
       "309_1     2.373744  0.232224  1.750936  ...  0.108336  0.427099   0.114783   \n",
       "309_2     2.292150  0.226972  1.596377  ...  0.104315  0.441581   0.111974   \n",
       "309_3     2.283337  0.230247  1.561316  ...  0.106219  0.435777   0.111883   \n",
       "309_4     2.152301  0.207004  1.595086  ...  0.111262  0.391691   0.130405   \n",
       "309_5     2.134014  0.192158  1.504230  ...  0.110694  0.434154   0.118481   \n",
       "\n",
       "           EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
       "MouseID                                                                       \n",
       "309_1    0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
       "309_2    0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
       "309_3    0.133362  0.127431  1.926427   Control  Memantine       C/S  c-CS-m  \n",
       "309_4    0.147444  0.146901  1.700563   Control  Memantine       C/S  c-CS-m  \n",
       "309_5    0.140314  0.148380  1.839730   Control  Memantine       C/S  c-CS-m  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has missing values.  The site:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "\n",
    "has an excellent summary of methods to deal with missing values.  Following the techniques there, create a new data frame `df1` where the missing values in each column are filled with the mean values from the non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for Down's Syndrome\n",
    "\n",
    "We will first predict the binary class label in `df1['Genotype']` which indicates if the mouse has Down's syndrome or not.  Get the string values in `df1['Genotype'].values` and convert this to a numeric vector `y` with 0 or 1.  You may wish to use the `np.unique` command with the `return_inverse=True` option (OR pandas.get_dummies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.unique(df1['Genotype'].values,return_inverse=True)[1]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predictors, get all but the last four columns of the dataframes.  Store the data matrix into `X`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(df1.iloc[:,:len(df.columns)-4].values)\n",
    "X_names = df1.columns[:-4]\n",
    "X=np.array(df1[X_names].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtr, Xts, ytr, yts = train_test_split(X,y,test_size=.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data with the `StandardScaler`.  Store the scaled values in `Xtr1` and `Xts1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr1 = scaler.fit_transform(Xtr)\n",
    "Xts1 = scaler.fit_transform(Xts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test with 30% allocated for test.  You can use the train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `LogisticRegression` object `logreg` and `fit` on the scaled training data.  Set the regularization level to `C=1e5` and use the optimizer `solver=liblinear`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1e5,solver='liblinear')\n",
    "logreg.fit(Xtr1,ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the classifer on test data.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506172839506173"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = logreg.predict(Xts1)\n",
    "acc = accuracy_score(yts, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a stem plot of the coefficients, `W` in the logistic regression model.  Use the `plt.stem()` function with the `use_line_collection=True` option.  You can get the coefficients from `logreg.coef_`, but you will need to reshape this to a 1D array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StemContainer object of 3 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W = np.reshape(logreg.coef_,(-1,1))\n",
    "plt.stem(W,use_line_collection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that `W[i]` is very large for a few components `i`.  These are the genes that are likely to be most involved in Down's Syndrome.   Below we will use L1 regression to enforce sparsity.  Find the names of the genes for two components `i` where the magnitude of `W[i]` is largest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two genes that have the largest weights are: ITSN1_N and APP_N\n"
     ]
    }
   ],
   "source": [
    "idx_arr = np.argsort(W,axis=0)\n",
    "print('The two genes that have the largest weights are:',X_names[idx_arr[-1]][0],'and',X_names[idx_arr[-2]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "To obtain a slightly more accurate result, now perform 10-fold cross validation and measure the average precision, recall and f1-score.  Note, that in performing the cross-validation, you will want to randomly permute the test and training sets using the `shuffle` option.  In this data set, all the samples from each class are bunched together, so shuffling is essential.  Print the accuracy across all the folds.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "- Shuffle the dataset randomly.\n",
    "- Split the dataset into k groups\n",
    "\n",
    "For each unique group:\n",
    "\n",
    "- Take the group as a hold out or test data set\n",
    "- Take the remaining groups as a training data set\n",
    "- Fit a model on the training set and evaluate it on the test set\n",
    "- Retain the evaluation score and discard the model\n",
    "- Summarize the skill of the model using the sample of model evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy scores across 10 folds are: [0.94444444 0.82407407 0.93518519 0.96296296 0.9537037  0.98148148\n",
      " 0.97222222 0.89814815 0.91666667 0.98148148]\n"
     ]
    }
   ],
   "source": [
    "import  sklearn.model_selection \n",
    "\n",
    "nfold = 10  # Number of folds\n",
    "\n",
    "# Create a k-fold object\n",
    "kf = sklearn.model_selection.KFold(n_splits=nfold)\n",
    "\n",
    " \n",
    "# Initialize arrays to hold values of the meeasurement scores across folds.\n",
    "acc_arr = np.zeros(nfold)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "recall_arr = np.zeros(nfold)\n",
    "fscore_arr = np.zeros(nfold)\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_shuffled, y_shuffled = shuffle(X, y)\n",
    "\n",
    "# Loop over the folds\n",
    "for isplit, Ind in enumerate(kf.split(X_shuffled)):\n",
    "    # Get the training/test data indices in the split\n",
    "    Itr, Its = Ind        \n",
    "\n",
    "    # Split the data (X_shuffled, y_shuffled) into training and test\n",
    "    Xtr = X_shuffled[Itr,:]\n",
    "    ytr = y_shuffled[Itr]\n",
    "    Xts = X_shuffled[Its,:]\n",
    "    yts = y_shuffled[Its]\n",
    "    # rescale X\n",
    "    scaler = StandardScaler()\n",
    "    Xtr1 = scaler.fit_transform(Xtr)\n",
    "    Xts1 = scaler.fit_transform(Xts)\n",
    "    # Fit data on training data        \n",
    "    # Measure the accuracy value on test data and store in the matrix Rsq\n",
    "    logreg = LogisticRegression(C=1e5,solver='liblinear')\n",
    "    logreg.fit(Xtr1,ytr)\n",
    "    y_pred = logreg.predict(Xts1)\n",
    "    # store the measures\n",
    "    acc_arr[isplit] = accuracy_score(yts, y_pred)\n",
    "    recall_arr[isplit] = precision_recall_fscore_support(yts, y_pred)[1][0]\n",
    "    fscore_arr[isplit] = precision_recall_fscore_support(yts, y_pred)[2][0]\n",
    "     \n",
    "print(\"The accuracy scores across 10 folds are:\",acc_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Now use the response variable in `df1['class']`.  This has 8 possible classes.  Use the `np.unique` funtion as before to convert this to a vector `y` with values 0 to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.unique(df1['class'].values,return_inverse=True)[1]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a multi-class logistic model by creating a `LogisticRegression` object, `logreg` and then calling the `logreg.fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, solver='liblinear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr, Xts, ytr, yts = train_test_split(X,y,test_size=.3,shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "Xtr1 = scaler.fit_transform(Xtr)\n",
    "Xts1 = scaler.fit_transform(Xts)\n",
    "logreg = LogisticRegression(C=1e5,solver='liblinear') \n",
    "logreg.fit(Xtr1,ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to measure errors in multi-class classification is with a *confusion matrix*.  A confusion matrix is a matrix `C` where `C[i,j]` is the number o where `ytrue==i` and `yhat==j`. You can use the `confusion_matrix` method in the `sklearn` package to compute the confusion matrix.\n",
    "\n",
    "\n",
    "Perform 10-fold cross validation, and measure the confusion matrix `C` on the test data in each fold using the `confusion_matrix` command.  Add the confusion matrix counts across all folds and then normalize the rows of the confusion matrix so that they sum to one.  Thus, each element `C[i,j]` will present the fraction of time `yhat=j` given `ytrue=i`.  Print the normalized confusion matrix.  You can use the command\n",
    "\n",
    "    print(np.array_str(C, precision=4, suppress_small=True))\n",
    "    \n",
    "to create a nicely formatted print.  Also print the overall mean and SE of the test accuracy across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9667 0.02   0.     0.     0.     0.0133 0.     0.    ]\n",
      " [0.0222 0.9704 0.     0.     0.0074 0.     0.     0.    ]\n",
      " [0.     0.0067 0.9933 0.     0.     0.     0.     0.    ]\n",
      " [0.0074 0.     0.     0.9926 0.     0.     0.     0.    ]\n",
      " [0.     0.0074 0.     0.     0.9926 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.0074 0.     0.9926 0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "The mean and SE of the accuracy scores across 10 folds are: 0.9879629629629629 0.011748682907823632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nfold = 10  # Number of folds\n",
    "\n",
    "# Create a k-fold object\n",
    "kf = sklearn.model_selection.KFold(n_splits=nfold)\n",
    "\n",
    " \n",
    "# Initialize arrays to hold accuracy scores across folds.\n",
    "acc_arr = np.zeros(nfold)\n",
    "\n",
    "# initialize C, a dict to store the C matrices\n",
    "C_dict = dict()\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_shuffled, y_shuffled = shuffle(X, y)\n",
    "\n",
    "# Loop over the folds\n",
    "for isplit, Ind in enumerate(kf.split(X_shuffled)):\n",
    "    # Get the training/test data indices in the split\n",
    "    Itr, Its = Ind        \n",
    "\n",
    "    # Split the data (X_shuffled, y_shuffled) into training and test\n",
    "    Xtr = X_shuffled[Itr,:]\n",
    "    ytr = y_shuffled[Itr]\n",
    "    Xts = X_shuffled[Its,:]\n",
    "    yts = y_shuffled[Its]\n",
    "    # rescale X\n",
    "    scaler = StandardScaler()\n",
    "    Xtr1 = scaler.fit_transform(Xtr)\n",
    "    Xts1 = scaler.fit_transform(Xts)\n",
    "    # Fit data on training data        \n",
    "    # Measure the accuracy value on test data and store in the matrix Rsq\n",
    "    logreg = LogisticRegression(C=1e5,solver='liblinear')\n",
    "    logreg.fit(Xtr1,ytr)\n",
    "    y_pred = logreg.predict(Xts1)\n",
    "    # store the accuracy\n",
    "    acc_arr[isplit] = accuracy_score(yts, y_pred)\n",
    "    # get the confusion matrix\n",
    "    C_dict[isplit] = confusion_matrix(yts,y_pred)\n",
    "\n",
    "\n",
    "# Add the confusion matrix counts across all folds \n",
    "C_sum = np.zeros([C_dict[0].shape[0],C_dict[0].shape[1]])\n",
    "for key, C_mtx in C_dict.items():\n",
    "    C_sum += C_mtx\n",
    "# and then normalize the rows of the confusion matrix so that they sum to one\n",
    "from sklearn.preprocessing import normalize\n",
    "C = normalize(C_sum, axis=1, norm='l1')\n",
    "# Print the normalized confusion matrix.\n",
    "print(np.array_str(C, precision=4, suppress_small=True))\n",
    "# print the overall mean and SE of the test accuracy across the folds\n",
    "print(\"The mean and SE of the accuracy scores across 10 folds are:\",np.mean(acc_arr),np.std(acc_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
